{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOvtxAYez3ZaM+Fu8/WOEtu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#**Mount your Google Drive. Make sure your workspace is uploaded to the drive**\n","#Navigate to Runtime and change the settings to GPU"],"metadata":{"id":"MPjY0C8lSSTf"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3AD5h_9iCJYi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762589818914,"user_tz":300,"elapsed":18943,"user":{"displayName":"Smrithi Siddagangaiah","userId":"12587236314556467415"}},"outputId":"6a1db613-6647-45d3-88a2-207f3c19a50b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#**You can run the below cells to verify the folder exists on the drive**"],"metadata":{"id":"EYXzDBzWStUs"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/hw10_workspace/src/model_generation\n","!ls"],"metadata":{"id":"94JP3Yp1MM3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762589911109,"user_tz":300,"elapsed":113,"user":{"displayName":"Smrithi Siddagangaiah","userId":"12587236314556467415"}},"outputId":"a5a76dc9-e22a-4ca0-cc79-1fd7cd9c0d28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/hw10_workspace/src/model_generation\n","dataset.py  eval.py  model.py  __pycache__  train.ipynb  util\n"]}]},{"cell_type":"markdown","source":["#**Install dependencies, and import necessary libraries**\n","\n"],"metadata":{"id":"t0hxCcm9UAOR"}},{"cell_type":"code","source":["import os, math, argparse, torch, random\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.optim import AdamW\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms as T\n","from PIL import Image\n","\n","from dataset import make_loaders   # from dataset.py\n","from model import ImageOnlySteerNet\n","\n","IMAGENET_MEAN = (0.485, 0.456, 0.406)\n","IMAGENET_STD  = (0.229, 0.224, 0.225)"],"metadata":{"id":"d-m3m0W5VFkg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[":\n","#**Q2.a Data Augmentation AND Preprocessing Pipeline**\n","In this section, you define how the input images are transformed\n","before being fed into the neural network.\n","There are two parts:\n","(1) `make_eval_tf()` - transformations for validation/test (NO augmentation)\n","(2) `make_train_tf()` - transformations for training (WITH augmentation)\n","\n","The idea is to help the model generalize better to unseen lighting\n","conditions, camera shifts, or image distortions by applying random\n","transformations during training.\n","\n","You are expected to:\n","→ Experiment with parameters inside `make_train_tf`\n","such as brightness, contrast, rotation, translation, and scale.\n","→ Leave `make_eval_tf()` unchanged.\n","→ Understand how these augmentations affect model performance.\n","\n","Hints:\n","- Increase brightness/contrast jitter slightly if dataset lighting varies.\n","- Small random affine transforms simulate the TurtleBot camera moving.\n","- `TopCrop` removes the top part of the frame (e.g., ceiling or wall)."],"metadata":{"id":"IKo8Uc9aUeme"}},{"cell_type":"code","source":["# ------------------ Augmentations ------------------\n","class TopCrop(torch.nn.Module):\n","    def __init__(self, frac: float): super().__init__(); self.frac = max(0.0, min(1.0, float(frac)))\n","    def forward(self, im: Image.Image):\n","        if self.frac <= 0: return im\n","        w, h = im.size; cut = int(h * self.frac)\n","        return im.crop((0, cut, w, h))\n","\n","def make_eval_tf(short_side: int, top_crop: float):\n","    return T.Compose([\n","        TopCrop(top_crop),\n","        T.Resize(short_side),          # keeps aspect ratio (short side -> short_side)\n","        T.CenterCrop(short_side),      # make square for ResNet\n","        T.ToTensor(),\n","        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n","    ])\n","\n","def make_train_tf(args):\n","    return T.Compose([\n","        TopCrop(args.top_crop),\n","        T.Resize(args.short_side),\n","        T.CenterCrop(args.short_side),\n","        T.ColorJitter(brightness=args.jitter_b,\n","                      contrast=args.jitter_c,\n","                      saturation=args.jitter_s,\n","                      hue=args.jitter_h),\n","        T.RandomAffine(\n","            degrees=args.affine_deg,\n","            translate=(args.affine_trans, args.affine_trans),\n","            scale=(args.affine_scale_min, args.affine_scale_max),\n","            interpolation=T.InterpolationMode.BILINEAR,\n","            fill=0,\n","        ),\n","        T.ToTensor(),\n","        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n","    ])\n","# ---------------------------------------------------"],"metadata":{"id":"ukRKBh6PYDKT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Q2.b Training Pipeline Set-Up**\n","# MODEL EVALUATION FUNCTION\n","This helper function evaluates the trained model on a dataset.\n","It computes two metrics:\n","- Mean Absolute Error (MAE)\n","- Root Mean Squared Error (RMSE)\n","\n","You do NOT need to modify this function.\n","\n","============================================================\n","# Helper: get_lr()\n","Returns the current learning rate from the optimizer.\n","Used for TensorBoard logging.\n","You do NOT need to modify this function."],"metadata":{"id":"MP6-B3Jlb1DF"}},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model, loader, device, mu, sigma):\n","    model.eval()\n","    se = mae = n = 0\n","    for x, _, y_std, y_raw, _ in loader:\n","        x = x.to(device, non_blocking=True)\n","        y_std = y_std.to(device, non_blocking=True)\n","        yhat_std = model(x)                 # [B]\n","        yhat_raw = yhat_std * sigma + mu    # [B]\n","        diff = (yhat_raw.cpu() - y_raw)     # [B]\n","        mae += diff.abs().sum().item()\n","        se  += (diff**2).sum().item()\n","        n   += y_raw.shape[0]\n","    mae /= max(1, n)\n","    rmse = math.sqrt(se / max(1, n))\n","    return mae, rmse\n","\n","def get_lr(optimizer):\n","    for pg in optimizer.param_groups:\n","        return pg.get(\"lr\", None)"],"metadata":{"id":"-eLIbdMgkdce"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Q2.c EXPERIMENT SETUP**\n","\n","The main training script below is where we:\n","--Define hyperparameters\n","--Prepare dataloaders\n","--Initialize model, optimizer, and loss function\n","--Configure TensorBoard logging\n","\n","For this question, you will define these variables manually. You will have to modify the main function according to your system. FIne tuning the model will give you better results. Please study the function properly and play with the parameters to get good results.\n","\n","============================================================\n","\n","#**Q2.d TRAINING LOOP**\n","In this section, you will complete the model training loop.\n","The code below iterates through multiple epochs and performs:\n"," 1️⃣ Forward pass (model prediction)\n"," 2️⃣ Loss computation\n"," 3️⃣ Backward pass (gradient computation)\n"," 4️⃣ Optimizer step (parameter update)\n"," 5️⃣ Logging metrics to TensorBoard\n","\n","You are expected to:\n","- Implement the forward pass and loss calculation (TODOs below)\n","- Understand how mixed precision (autocast) and GradScaler work\n","- Track and average MAE and loss across batches\n","\n"," ============================================================\n","\n","# **Q2.e VALIDATION, CHECKPOINTING, AND TEST EVALUATION**\n","After each epoch of training, we evaluate model performance\n","on the validation (or training) set, log results to TensorBoard,\n","and save the best model checkpoint based on lowest MAE.\n","Finally, once training completes, we evaluate the final model\n","on the test dataset to estimate its generalization performance.\n","You must:\n","• Understand how evaluate() is used to measure MAE/RMSE\n","• Observe when and why checkpoints are saved\n","• Record test metrics and analyze how well the model learned"],"metadata":{"id":"Vow-MsdblNYs"}},{"cell_type":"code","source":["def main():\n","    # ------------------ TODO: Define Hyperparameters ------------------\n","    epochs = 20\n","    bs = 64\n","    lr = 1e-4\n","    wd = 1e-4\n","    dropout = 0.1\n","    use_aug = True\n","    fp16 = True                 # Use mixed precision if supported\n","    pretrained = True\n","    freeze_backbone = False\n","    seed = 42\n","    logdir = \"runs/image_only\"\n","    ckpt_out = \"ckpt_best.pt\"\n","    # -----------------------------------------------------------------\n","\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Device: {device}\")\n","\n","    # ============================================================\n","    # Dataset Setup\n","    # ============================================================\n","    omega_sign = +1.0\n","    train_dl, val_dl, test_dl, stats = make_loaders(\n","        index=\"path/to/your/index_smooth.json\",\n","        root=\"path/to/your/merged_dataset\",\n","        bs=bs,\n","        hist_len=0,\n","        omega_sign=omega_sign,\n","        short_side=224,\n","        top_crop_frac=0.2\n","    )\n","    mu, sigma = stats[\"mu\"], stats[\"sigma\"]\n","    print(f\"Label standardization: mu={mu:.6f}, sigma={sigma:.6f}\")\n","\n","    # ============================================================\n","    # Data Augmentations\n","    # ============================================================\n","    eval_tf  = make_eval_tf(224, 0.2)\n","    train_tf = make_train_tf(argparse.Namespace(\n","        top_crop=0.2, short_side=224,\n","        jitter_b=0.12, jitter_c=0.12, jitter_s=0.10, jitter_h=0.02,\n","        affine_deg=3.0, affine_trans=0.02,\n","        affine_scale_min=0.95, affine_scale_max=1.05\n","    )) if use_aug else eval_tf\n","\n","    train_dl.dataset.img_tf = train_tf\n","    if val_dl:\n","        val_dl.dataset.img_tf = eval_tf\n","    if test_dl:\n","        test_dl.dataset.img_tf = eval_tf\n","\n","    print(f\"Augmentations: {'ON' if use_aug else 'OFF'} | top_crop=20% | short_side=224\")\n","\n","    # ============================================================\n","    # Model / Optimizer / Loss / AMP\n","    # ============================================================\n","    model = ImageOnlySteerNet(\n","        out_len=1,\n","        pretrained=pretrained,\n","        freeze_backbone=freeze_backbone,\n","        dropout=dropout,\n","    ).to(device)\n","\n","    opt = #####\n","    loss_fn = #####\n","    scaler = #####\n","\n","    writer = SummaryWriter(logdir)\n","    writer.add_text(\"hparams\", str({\n","        \"lr\": lr, \"bs\": bs, \"epochs\": epochs,\n","        \"use_aug\": use_aug, \"dropout\": dropout\n","    }))\n","    writer.add_scalar(\"data/mu\", mu, 0)\n","    writer.add_scalar(\"data/sigma\", sigma, 0)\n","\n","    best_mae = float(\"inf\")\n","    global_step = 0\n","\n","    # ============================================================\n","    # Training Loop\n","    # ============================================================\n","    for epoch in range(1, epochs + 1):\n","        model.train()\n","        running_loss = 0.0\n","        running_mae  = 0.0\n","        n_seen = 0\n","\n","        # Iterate over all batches\n","        for x, _, y_std, y_raw, _ in train_dl:\n","            x = x.to(device, non_blocking=True)\n","            y_std = y_std.to(device, non_blocking=True)\n","\n","            # Reset gradients\n","            ##### your code here #####\n","\n","            # Forward pass\n","            ##### your code here #####\n","\n","            # Backward pass + optimizer update\n","            ##### your code here #####\n","\n","            # Log current batch loss and learning rate\n","            writer.add_scalar(\"train/step_loss\", loss.item(), global_step)\n","            lr_now = get_lr(opt)\n","            if lr_now is not None:\n","                writer.add_scalar(\"train/lr\", lr_now, global_step)\n","\n","            # Compute metrics (MAE in raw units)\n","            with torch.no_grad():\n","                yhat_raw = (yhat_std * sigma + mu).cpu()\n","                mae_batch = (yhat_raw - y_raw).abs().sum().item()\n","                running_mae  += mae_batch\n","                running_loss += loss.item() * y_std.shape[0]\n","                n_seen += y_std.shape[0]\n","\n","            global_step += 1\n","\n","        # ============================================================\n","        # Compute epoch averages\n","        # ============================================================\n","        train_loss = running_loss / max(1, n_seen)\n","        train_mae  = running_mae  / max(1, n_seen)\n","\n","        writer.add_scalar(\"train/epoch_loss\", train_loss, epoch)\n","        writer.add_scalar(\"train/epoch_MAE\",  train_mae,  epoch)\n","\n","        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Train MAE: {train_mae:.4f}\")\n"],"metadata":{"id":"Wrh8oGYtkjLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Run the below cell to test the model.**\n","Q2.f What does the graph indicate? Is the loss function decreasing?"],"metadata":{"id":"PFiMFnTJcFU0"}},{"cell_type":"code","source":["python3 eval.py --index data/processed/merged_dataset/index_smooth.json --root  data/processed/merged_dataset --ckpt  ckpt_best.pt --split test --outdir eval_out --save-overlays --flip-sign --short-side 224 --top-crop 0.2"],"metadata":{"id":"cDPTLMA8bkdJ"},"execution_count":null,"outputs":[]}]}